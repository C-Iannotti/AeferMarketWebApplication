{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7de3cf73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Invoice ID Branch       City Customer type  Gender  \\\n",
      "0    750-67-8428      A     Yangon        Member  Female   \n",
      "1    226-31-3081      C  Naypyitaw        Normal  Female   \n",
      "2    631-41-3108      A     Yangon        Normal    Male   \n",
      "3    123-19-1176      A     Yangon        Member    Male   \n",
      "4    373-73-7910      A     Yangon        Normal    Male   \n",
      "..           ...    ...        ...           ...     ...   \n",
      "995  233-67-5758      C  Naypyitaw        Normal    Male   \n",
      "996  303-96-2227      B   Mandalay        Normal  Female   \n",
      "997  727-02-1313      A     Yangon        Member    Male   \n",
      "998  347-56-2442      A     Yangon        Normal    Male   \n",
      "999  849-09-3807      A     Yangon        Member  Female   \n",
      "\n",
      "               Product line  Unit price  Quantity   Tax 5%      Total  \\\n",
      "0         Health and beauty       74.69         7  26.1415   548.9715   \n",
      "1    Electronic accessories       15.28         5   3.8200    80.2200   \n",
      "2        Home and lifestyle       46.33         7  16.2155   340.5255   \n",
      "3         Health and beauty       58.22         8  23.2880   489.0480   \n",
      "4         Sports and travel       86.31         7  30.2085   634.3785   \n",
      "..                      ...         ...       ...      ...        ...   \n",
      "995       Health and beauty       40.35         1   2.0175    42.3675   \n",
      "996      Home and lifestyle       97.38        10  48.6900  1022.4900   \n",
      "997      Food and beverages       31.84         1   1.5920    33.4320   \n",
      "998      Home and lifestyle       65.82         1   3.2910    69.1110   \n",
      "999     Fashion accessories       88.34         7  30.9190   649.2990   \n",
      "\n",
      "          Date   Time      Payment    cogs  gross margin percentage  \\\n",
      "0     1/5/2019  13:08      Ewallet  522.83                 4.761905   \n",
      "1     3/8/2019  10:29         Cash   76.40                 4.761905   \n",
      "2     3/3/2019  13:23  Credit card  324.31                 4.761905   \n",
      "3    1/27/2019  20:33      Ewallet  465.76                 4.761905   \n",
      "4     2/8/2019  10:37      Ewallet  604.17                 4.761905   \n",
      "..         ...    ...          ...     ...                      ...   \n",
      "995  1/29/2019  13:46      Ewallet   40.35                 4.761905   \n",
      "996   3/2/2019  17:16      Ewallet  973.80                 4.761905   \n",
      "997   2/9/2019  13:22         Cash   31.84                 4.761905   \n",
      "998  2/22/2019  15:33         Cash   65.82                 4.761905   \n",
      "999  2/18/2019  13:28         Cash  618.38                 4.761905   \n",
      "\n",
      "     gross income  Rating  \n",
      "0         26.1415     9.1  \n",
      "1          3.8200     9.6  \n",
      "2         16.2155     7.4  \n",
      "3         23.2880     8.4  \n",
      "4         30.2085     5.3  \n",
      "..            ...     ...  \n",
      "995        2.0175     6.2  \n",
      "996       48.6900     4.4  \n",
      "997        1.5920     7.7  \n",
      "998        3.2910     4.1  \n",
      "999       30.9190     6.6  \n",
      "\n",
      "[1000 rows x 17 columns]\n",
      "    Branch            Product line       Date  Quantity\n",
      "0        A       Health and beauty 2019-01-05         7\n",
      "1        C  Electronic accessories 2019-03-08         5\n",
      "2        A      Home and lifestyle 2019-03-03         7\n",
      "3        A       Health and beauty 2019-01-27         8\n",
      "4        A       Sports and travel 2019-02-08         7\n",
      "..     ...                     ...        ...       ...\n",
      "995      C       Health and beauty 2019-01-29         1\n",
      "996      B      Home and lifestyle 2019-03-02        10\n",
      "997      A      Food and beverages 2019-02-09         1\n",
      "998      A      Home and lifestyle 2019-02-22         1\n",
      "999      A     Fashion accessories 2019-02-18         7\n",
      "\n",
      "[1000 rows x 4 columns]\n",
      "     Branch            Product line       Date  Quantity\n",
      "0         A  Electronic accessories 2019-01-01        10\n",
      "1         A  Electronic accessories 2019-01-02         0\n",
      "2         A  Electronic accessories 2019-01-03         0\n",
      "3         A  Electronic accessories 2019-01-04         0\n",
      "4         A  Electronic accessories 2019-01-05         7\n",
      "...     ...                     ...        ...       ...\n",
      "1597      C       Sports and travel 2019-03-26         0\n",
      "1598      C       Sports and travel 2019-03-27         0\n",
      "1599      C       Sports and travel 2019-03-28         0\n",
      "1600      C       Sports and travel 2019-03-29         0\n",
      "1601      C       Sports and travel 2019-03-30         0\n",
      "\n",
      "[1602 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "data = pd.read_csv(\"../../data/supermarket_sales - Sheet1.csv\")\n",
    "print(data)\n",
    "\n",
    "data = data[[\"Branch\", \"Product line\", \"Date\", \"Quantity\"]]\n",
    "data[\"Date\"] = pd.to_datetime(data[\"Date\"])\n",
    "print(data)\n",
    "\n",
    "min_date = data[\"Date\"].min()\n",
    "max_date = data[\"Date\"].max()\n",
    "delta = max_date - min_date\n",
    "\n",
    "for i in range(delta.days + 1):\n",
    "    day = min_date + timedelta(days=i)\n",
    "    for branch in pd.unique(data[\"Branch\"]):\n",
    "        for product_line in pd.unique(data[\"Product line\"]):\n",
    "            data.loc[len(data)] = [branch, product_line, day, 0]\n",
    "data = data.groupby([\"Branch\", \"Product line\", \"Date\"])[\"Quantity\"].sum().reset_index()\n",
    "print(data)\n",
    "data.to_pickle(\"model_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c446a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Branch            Product line       Date  Quantity\n",
      "0         A  Electronic accessories 2019-01-01        10\n",
      "1         A  Electronic accessories 2019-01-02         0\n",
      "2         A  Electronic accessories 2019-01-03         0\n",
      "3         A  Electronic accessories 2019-01-04         0\n",
      "4         A  Electronic accessories 2019-01-05         7\n",
      "...     ...                     ...        ...       ...\n",
      "1597      C       Sports and travel 2019-03-26         0\n",
      "1598      C       Sports and travel 2019-03-27         0\n",
      "1599      C       Sports and travel 2019-03-28         0\n",
      "1600      C       Sports and travel 2019-03-29         0\n",
      "1601      C       Sports and travel 2019-03-30         0\n",
      "\n",
      "[1602 rows x 4 columns]\n",
      "       Month  Class  A  B  C  Electronic accessories  Fashion accessories  \\\n",
      "0          1      2  1  0  0                       1                    0   \n",
      "1          1      0  1  0  0                       1                    0   \n",
      "2          1      0  1  0  0                       1                    0   \n",
      "3          1      2  1  0  0                       1                    0   \n",
      "4          1      0  1  0  0                       1                    0   \n",
      "...      ...    ... .. .. ..                     ...                  ...   \n",
      "28579      3      0  0  0  1                       0                    0   \n",
      "28580      3      0  0  0  1                       0                    0   \n",
      "28581      3      0  0  0  1                       0                    0   \n",
      "28582      3      0  0  0  1                       0                    0   \n",
      "28583      3      0  0  0  1                       0                    0   \n",
      "\n",
      "       Food and beverages  Health and beauty  Home and lifestyle  ...  4  5  \\\n",
      "0                       0                  0                   0  ...  7  0   \n",
      "1                       0                  0                   0  ...  0  4   \n",
      "2                       0                  0                   0  ...  4  7   \n",
      "3                       0                  0                   0  ...  7  0   \n",
      "4                       0                  0                   0  ...  0  0   \n",
      "...                   ...                ...                 ...  ... .. ..   \n",
      "28579                   0                  0                   0  ...  0  0   \n",
      "28580                   0                  0                   0  ...  0  0   \n",
      "28581                   0                  0                   0  ...  0  9   \n",
      "28582                   0                  0                   0  ...  9  5   \n",
      "28583                   0                  0                   0  ...  5  0   \n",
      "\n",
      "       6   7   8   9  10  11  12  13  \n",
      "0      4   7   0   0   0  10   6   0  \n",
      "1      7   0   0   0  10   6   0   9  \n",
      "2      0   0   0  10   6   0   9   0  \n",
      "3      0   0  10   6   0   9   0   0  \n",
      "4      0  10   6   0   9   0   0   5  \n",
      "...   ..  ..  ..  ..  ..  ..  ..  ..  \n",
      "28579  0   9   5   0   0   0   5   0  \n",
      "28580  9   5   0   0   0   5   0   0  \n",
      "28581  5   0   0   0   5   0   0   0  \n",
      "28582  0   0   0   5   0   0   0   0  \n",
      "28583  0   0   5   0   0   0   0   0  \n",
      "\n",
      "[28584 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_pickle(\"./model_data.pkl\")\n",
    "print(data)\n",
    "\n",
    "train_data = pd.DataFrame(columns=[\"Branch\", \"Product line\", \"Month\"] + [f\"{i}\" for i in range(14)] + [\"Class\"])\n",
    "branches = pd.unique(data[\"Branch\"])\n",
    "product_lines = pd.unique(data[\"Product line\"])\n",
    "\n",
    "for branch in branches:\n",
    "    for product_line in product_lines:\n",
    "        cur_frame = data[(data[\"Branch\"] == branch) & (data[\"Product line\"] == product_line)]\n",
    "        values = data[\"Quantity\"]\n",
    "        cur_slide = values.iloc[:14].to_list()\n",
    "        for i in range(14, values.shape[0]):\n",
    "            label = 1\n",
    "            \n",
    "            if cur_slide[-1] - values[i] >= cur_slide[-1] * 0.33:\n",
    "                label = 0\n",
    "            elif cur_slide[-1] - values[i] <= cur_slide[-1] * -0.33:\n",
    "                label = 2\n",
    "            train_data.loc[len(train_data.index)] = [branch, product_line, data.iloc[i][\"Date\"].month] + cur_slide + [label]\n",
    "            \n",
    "            cur_slide.pop(0)\n",
    "            cur_slide.append(values[i])\n",
    "            \n",
    "train_data = pd.concat([train_data, pd.get_dummies(train_data[\"Branch\"])], axis=1)\n",
    "train_data = pd.concat([train_data, pd.get_dummies(train_data[\"Product line\"])], axis=1)\n",
    "\n",
    "train_data.pop(\"Branch\")\n",
    "train_data.pop(\"Product line\")\n",
    "train_data = train_data[[c for c in train_data if c not in [f\"{i}\" for i in range(14)]] \n",
    "       + [f\"{i}\" for i in range(14)]]\n",
    "            \n",
    "print(train_data)\n",
    "train_data.to_pickle(\"transformed_model_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5591e96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6032745591939547\n",
      "0.0535264483627204\n",
      "0.3431989924433249\n",
      "\n",
      "0.39371602584170534\n",
      "0.38412499644249654\n",
      "0.22215897771579815\n",
      "\n",
      "0.3898479478678404\n",
      "0.3810449296901795\n",
      "0.22910712244198012\n",
      "\n",
      "0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_pickle(\"./transformed_model_data.pkl\")\n",
    "#print(data)\n",
    "train_data = data.sample(frac=0.8)\n",
    "test_data = data.drop(train_data.index)\n",
    "\n",
    "train_0 = train_data[train_data[\"Class\"] == 0]\n",
    "train_1 = train_data[train_data[\"Class\"] == 1]\n",
    "train_2 = train_data[train_data[\"Class\"] == 2]\n",
    "max_train = (train_0 if train_0.shape[0] >= train_1.shape[0] and train_0.shape[0] >= train_2.shape[0] else\n",
    "             train_1 if train_1.shape[0] >= train_0.shape[0] and train_1.shape[0] >= train_2.shape[0] else\n",
    "             train_2)\n",
    "\n",
    "test_0 = test_data[test_data[\"Class\"] == 0]\n",
    "test_1 = test_data[test_data[\"Class\"] == 1]\n",
    "test_2 = test_data[test_data[\"Class\"] == 2]\n",
    "max_test = (test_0 if test_0.shape[0] >= test_1.shape[0] and test_0.shape[0] >= test_2.shape[0] else\n",
    "             test_1 if test_1.shape[0] >= test_0.shape[0] and test_1.shape[0] >= test_2.shape[0] else\n",
    "             test_2)\n",
    "\n",
    "for data_item in [train_0, train_1, train_2]:\n",
    "    cur_num = data_item.shape[0]\n",
    "    while cur_num + data_item.shape[0] < max_train.shape[0]:\n",
    "        train_data = pd.concat([train_data, data_item])\n",
    "        cur_num += data_item.shape[0]\n",
    "\n",
    "for data_item in [test_0, test_1, test_2]:\n",
    "    cur_num = data_item.shape[0]\n",
    "    while cur_num + data_item.shape[0] < max_test.shape[0]:\n",
    "        test_data = pd.concat([test_data, data_item])\n",
    "        cur_num += data_item.shape[0]\n",
    "        \n",
    "print((data[\"Class\"] == 0).sum() / data.shape[0])\n",
    "print((data[\"Class\"] == 1).sum() / data.shape[0])\n",
    "print((data[\"Class\"] == 2).sum() / data.shape[0])\n",
    "print()\n",
    "\n",
    "print((train_data[\"Class\"] == 0).sum() / train_data.shape[0])\n",
    "print((train_data[\"Class\"] == 1).sum() / train_data.shape[0])\n",
    "print((train_data[\"Class\"] == 2).sum() / train_data.shape[0])\n",
    "print()\n",
    "\n",
    "print((test_data[\"Class\"] == 0).sum() / test_data.shape[0])\n",
    "print((test_data[\"Class\"] == 1).sum() / test_data.shape[0])\n",
    "print((test_data[\"Class\"] == 2).sum() / test_data.shape[0])\n",
    "print()\n",
    "\n",
    "print(pd.merge(train_data, test_data).shape[0])\n",
    "print()\n",
    "\n",
    "train_data.to_pickle(\"train_data.pkl\")\n",
    "test_data.to_pickle(\"test_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "77c91081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "138/138 [==============================] - 1s 1ms/step - loss: 0.9788 - categorical_crossentropy: 9.8758e-08 - mean_squared_error: 0.9788\n",
      "Epoch 2/10\n",
      "138/138 [==============================] - 0s 1ms/step - loss: 0.4932 - categorical_crossentropy: 9.8758e-08 - mean_squared_error: 0.4932\n",
      "Epoch 3/10\n",
      "138/138 [==============================] - 0s 1ms/step - loss: 0.3987 - categorical_crossentropy: 9.8758e-08 - mean_squared_error: 0.3987\n",
      "Epoch 4/10\n",
      "138/138 [==============================] - 0s 1ms/step - loss: 0.3456 - categorical_crossentropy: 9.8758e-08 - mean_squared_error: 0.3456\n",
      "Epoch 5/10\n",
      "138/138 [==============================] - 0s 1ms/step - loss: 0.3086 - categorical_crossentropy: 9.8758e-08 - mean_squared_error: 0.3086\n",
      "Epoch 6/10\n",
      "138/138 [==============================] - 0s 1ms/step - loss: 0.2830 - categorical_crossentropy: 9.8758e-08 - mean_squared_error: 0.2830\n",
      "Epoch 7/10\n",
      "138/138 [==============================] - 0s 1ms/step - loss: 0.2589 - categorical_crossentropy: 9.8758e-08 - mean_squared_error: 0.2589\n",
      "Epoch 8/10\n",
      "138/138 [==============================] - 0s 1ms/step - loss: 0.2412 - categorical_crossentropy: 9.8758e-08 - mean_squared_error: 0.2412\n",
      "Epoch 9/10\n",
      "138/138 [==============================] - 0s 1ms/step - loss: 0.2285 - categorical_crossentropy: 9.8758e-08 - mean_squared_error: 0.2285\n",
      "Epoch 10/10\n",
      "138/138 [==============================] - 0s 1ms/step - loss: 0.2130 - categorical_crossentropy: 9.8758e-08 - mean_squared_error: 0.2130\n",
      "Valid Accuracy:  0.7563537012266272\n",
      "Valid Accuracy:  0.7448267977592318\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "train_data = pd.read_pickle(\"./train_data.pkl\")\n",
    "test_data = pd.read_pickle(\"./test_data.pkl\")\n",
    "train_class = train_data.pop(\"Class\")\n",
    "test_class = test_data.pop(\"Class\")\n",
    "\n",
    "input_data = tf.convert_to_tensor(train_data.values.reshape(-1, 1, train_data.shape[1]))\n",
    "input_labels = tf.convert_to_tensor(train_class.values.reshape(-1, 1, 1), dtype=tf.float32)\n",
    "valid_data = tf.convert_to_tensor(test_data.values.reshape(-1, 1, test_data.shape[1]))\n",
    "valid_labels = tf.convert_to_tensor(test_class.values.reshape(-1, 1, 1), dtype=tf.float32)\n",
    "\n",
    "#print(input_data)\n",
    "#print(input_labels)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(units=32, activation=\"relu\"),\n",
    "    layers.Dense(units=32, activation=\"relu\"),\n",
    "    layers.Dense(units=1),\n",
    "    layers.Reshape([1,-1])\n",
    "])\n",
    "loss = keras.losses.MeanSquaredError()\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=0.005)\n",
    "metrics = [keras.metrics.CategoricalCrossentropy(), keras.metrics.MeanSquaredError()]\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    metrics=metrics\n",
    ")\n",
    "model.fit(x=input_data, y=input_labels, epochs=10, batch_size=BATCH_SIZE)\n",
    "print(\"Valid Accuracy: \", float(tf.divide(tf.reduce_sum(tf.cast(tf.equal(tf.round(model(input_data)), input_labels), tf.int32)), tf.shape(input_labels)[0])))\n",
    "print(\"Valid Accuracy: \", float(tf.divide(tf.reduce_sum(tf.cast(tf.equal(tf.round(model(valid_data)), valid_labels), tf.int32)), tf.shape(valid_labels)[0])))\n",
    "\n",
    "model.save(\"./model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b94ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
